# SRUTHI-AI Environment Configuration - 100% Offline Mode
# No API keys required - everything runs locally!

# ============================================================================
# LOCAL MODEL SETTINGS
# ============================================================================
# Path to your GGUF model file (required for offline operation)
# Download models from: https://huggingface.co/models?search=gguf
GGUF_MODEL_PATH=C:\Users\JATOTHU ANAND\Desktop\Smart Real-time Unified Tool for Human-AI Interaction sruthi-ai\assistant\codellama-7b-instruct.Q4_K_M.gguf

# ============================================================================
# GPU SETTINGS
# ============================================================================
# Use GPU for faster inference (requires NVIDIA GPU with CUDA)
GGUF_USE_GPU=true

# Number of model layers to offload to GPU (0-40 for 7B models)
# Higher = faster but uses more VRAM
# Recommended: 35 for 6GB VRAM, 0 for CPU-only
GGUF_GPU_LAYERS=35

# ============================================================================
# SPEECH RECOGNITION SETTINGS
# ============================================================================
# Whisper model size: tiny, base, small, medium, large
# Larger = more accurate but slower
WHISPER_MODEL=small

# Use GPU for speech recognition (faster)
WHISPER_DEVICE=cuda

# ============================================================================
# TEXT-TO-SPEECH SETTINGS
# ============================================================================
# Speech rate (words per minute): 100-200 recommended
PYTTSX3_RATE=160

# Volume (0.0 to 1.0)
PYTTSX3_VOLUME=0.9

# ============================================================================
# SYSTEM PREFERENCES
# ============================================================================
# Enable debug output
DEBUG_MODE=true

# Auto-save conversations
AUTO_SAVE_CONVERSATIONS=true

# Save after this many messages
AUTO_SAVE_THRESHOLD=4
