# Smart Assistant - 100% Offline AI Voice Assistant

ğŸ¤– **A Modern, ChatGPT-Style Voice Assistant** with GPU-accelerated STT, Local LLM, and Advanced PyQt6 GUI - Completely Offline!

## âœ¨ Features

- ğŸ¤ **Speech Recognition**: GPU-accelerated Whisper (faster-whisper) - 100% Offline
- ğŸ§  **Local AI Brain**: GGUF models via llama-cpp-python - No Internet Required
- ğŸ”Š **Text-to-Speech**: Pyttsx3 (offline only)
- ğŸ¨ **Modern ChatGPT-Style GUI**: Dark-themed PyQt6 interface with chat history sidebar
- ğŸ’¬ **Chat History**: Persistent conversations with sidebar navigation
- ğŸ¬ **Smooth Animations**: PyQt6 animations for professional feel
- âš™ï¸ **System Commands**: Control volume, open apps, search Chrome/YouTube
- ğŸ”’ **100% Privacy**: All processing happens locally - ZERO internet usage
- âš¡ **Non-blocking UI**: Threading ensures GUI never freezes
- ğŸŒ™ **Dark Theme**: Modern, easy-on-the-eyes interface

## ğŸ—ï¸ Architecture

```
MVC (Model-View-Controller) Pattern:
â”œâ”€â”€ Model (core/)       - Business logic (listener, brain, speaker)
â”œâ”€â”€ View (gui/)         - PyQt6 ChatGPT-style interface
â””â”€â”€ Controller (main.py) - Coordination
```

## ğŸ“‹ Prerequisites

### 1. **Python 3.10+**
Ensure Python is installed and available in PATH.

### 2. **GGUF Model** (Required)
Download a GGUF model for local LLM inference:
- [Hugging Face GGUF Models](https://huggingface.co/models?search=gguf)
- Recommended: CodeLlama 7B, Mistral 7B, or Llama 3 8B
- Place the model file in your preferred location
- Update the path in `.env` file

### 3. **NVIDIA GPU** (Optional but Recommended)
For GPU-accelerated speech recognition and LLM inference.
- Works on CPU too, but slower!

## ğŸš€ Installation

### Step 1: Clone/Download Project
```bash
cd "c:\Users\JATOTHU ANAND\Desktop\sruthi ai"
```

### Step 2: Activate Virtual Environment
```bash
# PowerShell (Windows)
.\env_sruthi\Scripts\Activate.ps1

# If you get execution policy error:
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Configure Environment
```bash
# Copy example environment file
copy .env.example .env

# Edit .env and set your GGUF model path
notepad .env
```

## ğŸ¯ Usage

### Running the Application
```bash
# Make sure env_sruthi is activated
.\env_sruthi\Scripts\Activate.ps1

# Run Smart Assistant
python main.py
```

### Using the Interface

**Modern ChatGPT-Style Interface:**
- **Left Sidebar**: Browse and load previous conversations
- **Chat Area**: Message bubbles with smooth animations  
- **Input Box**: Type messages or use voice input
- **Voice Toggle**: Control voice output per message (ğŸ”Š/ğŸ”‡)

**Features:**
1. **Text Input**: Type your message and press Enter or click Send
2. **Voice Input**: Click ğŸ¤ microphone button and speak
3. **Voice Control**: Toggle ğŸ”Š button to enable/disable voice output
4. **Chat History**: Click any conversation in sidebar to load it
5. **New Chat**: Click "+ New Chat" to start fresh conversation
6. **System Commands**: 
   - "Increase volume"
   - "Search python tutorials on Chrome"
   - "Find cooking videos on YouTube"
   - "Open settings"

## âš™ï¸ System Commands

Smart Assistant can execute system commands naturally:

**Volume Control:**
```
"Increase the volume"
"Turn volume down"
"Set volume to 50"
"Mute"
```

**Search:**
```
"Search machine learning on Chrome"
"Find recipe videos on YouTube"
```

**System:**
```
"Open settings"
"Open calculator"
```

## ğŸ› ï¸ Configuration

Edit `utils/config.py` or `.env` file to customize:

```python
# Whisper Model: tiny, base, small, medium, large
WHISPER_MODEL = "small"  # Default: optimized for 6GB VRAM

# GGUF Model Path
GGUF_MODEL_PATH = "path/to/your/model.gguf"

# GPU Settings
GGUF_GPU_LAYERS = 35  # Adjust based on your VRAM
GGUF_USE_GPU = True

# TTS Voice Settings
PYTTSX3_RATE = 160  # Words per minute
PYTTSX3_VOLUME = 0.9  # 0.0 to 1.0
```

## ğŸ“ Project Structure

```
sruthi ai/
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ .env.example           # Environment configuration template
â”œâ”€â”€ env_sruthi/            # Virtual environment
â”œâ”€â”€ assets/                # Temp audio files
â”œâ”€â”€ data/                  # Conversation memory
â”œâ”€â”€ core/                  # MVC Model - Business Logic
â”‚   â”œâ”€â”€ listener.py       # Speech-to-Text (Whisper)
â”‚   â”œâ”€â”€ brain.py          # LLM Integration (GGUF)
â”‚   â”œâ”€â”€ speaker.py        # Text-to-Speech (Pyttsx3)
â”‚   â””â”€â”€ memory.py         # Conversation memory
â”œâ”€â”€ gui/                   # MVC View - User Interface
â”‚   â””â”€â”€ app_chatgpt_style.py  # Modern ChatGPT-style GUI
â”œâ”€â”€ models/                # LLM abstraction layer
â”œâ”€â”€ tools/                 # System tools
â”‚   â”œâ”€â”€ applications.py   # App launcher & web search
â”‚   â”œâ”€â”€ files.py          # File operations
â”‚   â””â”€â”€ system.py         # System controls & volume
â”œâ”€â”€ intelligence/          # Command parsing
â”‚   â””â”€â”€ command_parser.py # Natural language command detection
â””â”€â”€ utils/                 # Utilities
    â””â”€â”€ config.py         # Configuration settings
```

## âš ï¸ Troubleshooting

### "GGUF model not found"
- Make sure you downloaded a GGUF model
- Update `GGUF_MODEL_PATH` in `.env` file with correct path
- Verify file exists at the specified location

### "No NVIDIA GPU detected"
- Normal on CPU-only systems
- Will use CPU mode (slower but functional)
- Check with: `nvidia-smi`

### "Microphone not detected"
- Check microphone permissions in Windows Settings
- Ensure microphone is connected and set as default

### CUDA/GPU Issues
- Install CUDA Toolkit 11.8+ from NVIDIA
- Install PyTorch with CUDA support:
  ```bash
  pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
  ```

## ğŸ“Š System Requirements

### Minimum
- CPU: Intel i5 / AMD Ryzen 5
- RAM: 8GB
- Disk: 5GB free space (+ model size)
- OS: Windows 10/11

### Recommended
- GPU: NVIDIA RTX 3050 (6GB VRAM) or better
- RAM: 16GB
- CPU: Modern multi-core processor
- OS: Windows 11

## ğŸ”’ Privacy Features

- âœ… Speech recognition: 100% local (faster-whisper)
- âœ… AI reasoning: 100% local (GGUF model)
- âœ… Text-to-speech: 100% local (pyttsx3)
- âœ… **NO data sent to external servers**
- âœ… **NO internet connection required**
- âœ… **NO API keys needed**

## ğŸ“ License

Created for educational purposes. Feel free to modify and distribute.

## ğŸ™ Acknowledgments

- **faster-whisper**: GPU-accelerated Whisper implementation
- **llama-cpp-python**: Local GGUF model inference
- **PyQt6**: Modern Python GUI framework
- **pyttsx3**: Offline text-to-speech

---

**Made with â¤ï¸ for privacy-conscious AI enthusiasts**

**ğŸ” 100% Offline | ğŸš« Zero Tracking | ğŸ’¯ Complete Privacy**
